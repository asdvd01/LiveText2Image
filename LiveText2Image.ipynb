{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyODIpobPLfBJsDP1iPvvN74"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing dependencies"
      ],
      "metadata": {
        "id": "c__eifP7N9A_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iOFomnINjja"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install gradio\n",
        "!pip install accelerate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model and running once so required files are available"
      ],
      "metadata": {
        "id": "gvhjbMNaOT07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "def text2image(prompt):\n",
        "    pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "    pipe.to(\"cuda\")\n",
        "    image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
        "    return image"
      ],
      "metadata": {
        "id": "vq231zISPY48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2image(\"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\")"
      ],
      "metadata": {
        "id": "HoyRU3VUPhZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the gradio server\n",
        "TODO: Using live parameter in the Interface to make the whole process trigger automatically without clicking on submit is breaking currently."
      ],
      "metadata": {
        "id": "BVKp0fNBWSZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "def text2image(prompt):\n",
        "    pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n",
        "    pipe.to(\"cuda\")\n",
        "    image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
        "    return image\n",
        "\n",
        "interface = gr.Interface(fn=text2image, inputs=\"text\", outputs=\"image\")\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "K-afb97UOXM9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}